{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import streamlit as st\n",
    "from dotenv import load_dotenv\n",
    "from qdrant_client import QdrantClient\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Qdrant\n",
    "from langchain_community.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.runnable import RunnableParallel, RunnablePassthrough, RunnableLambda\n",
    "from ragas.evaluation import evaluate\n",
    "from ragas.metrics import faithfulness, answer_relevancy, context_precision, context_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega variáveis de ambiente\n",
    "load_dotenv()\n",
    "QDRANT_URL = os.getenv(\"QDRANT_URL\")\n",
    "QDRANT_API_KEY = os.getenv(\"QDRANT_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    \"\"\"Formata os documentos recuperados.\"\"\"\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    st.title(\"Vehicle Manuals QA with RAGAS Evaluation\")\n",
    "\n",
    "    # Entrada do usuário\n",
    "    question = st.text_input(\"Digite sua pergunta:\")\n",
    "\n",
    "    if question:\n",
    "        # Inicialização de embeddings e modelo\n",
    "        # Ajuste o nome do modelo de embeddings conforme necessário\n",
    "        local_embeddings = HuggingFaceEmbeddings(\n",
    "            model_name=\"intfloat/multilingual-e5-large\",\n",
    "            model_kwargs={'trust_remote_code': True}\n",
    "        )\n",
    "        model = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "        # Cria o cliente Qdrant\n",
    "        try:\n",
    "            qdrant_client = QdrantClient(\n",
    "                url=QDRANT_URL,\n",
    "                api_key=QDRANT_API_KEY,\n",
    "            )\n",
    "\n",
    "            # Instancia o Qdrant VectorStore já apontando para a coleção existente\n",
    "            vectorstore = Qdrant(\n",
    "                client=qdrant_client,\n",
    "                collection_name=\"fluidos_chunkby-page_overlap0_multilingual-e5-large\",\n",
    "                embedding=local_embeddings\n",
    "            )\n",
    "        except Exception as e:\n",
    "            st.error(f\"Erro ao conectar ao Qdrant: {e}\")\n",
    "            return\n",
    "\n",
    "        retriever = vectorstore.as_retriever()\n",
    "\n",
    "        # Prompt do RAG\n",
    "        RAG_TEMPLATE = \"\"\"\n",
    "        Você é um assistente para tarefas de perguntas e respostas. Use os seguintes trechos de contexto recuperado para responder à pergunta.\n",
    "        Se você não souber a resposta, simplesmente diga que não sabe.\n",
    "        <context>{context}</context> Responda à seguinte pergunta: {question}\"\"\"\n",
    "\n",
    "        rag_prompt = ChatPromptTemplate.from_template(RAG_TEMPLATE)\n",
    "\n",
    "        # Chain de execução do RAG\n",
    "        rag_chain_from_docs = (\n",
    "            RunnablePassthrough.assign(context=(lambda x: format_docs(x[\"context\"])))\n",
    "            | rag_prompt\n",
    "            | model\n",
    "            | RunnableLambda(lambda x: x.content if hasattr(x, 'content') else x)\n",
    "        )\n",
    "\n",
    "        rag_chain_with_source = RunnableParallel(\n",
    "            {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "        ).assign(answer=rag_chain_from_docs)\n",
    "\n",
    "        # Execução da cadeia RAG\n",
    "        try:\n",
    "            result = rag_chain_with_source.invoke(question)\n",
    "        except Exception as e:\n",
    "            st.error(f\"Erro ao processar a cadeia RAG: {e}\")\n",
    "            return\n",
    "\n",
    "        # Exibição da pergunta e resposta\n",
    "        st.subheader(\"Pergunta:\")\n",
    "        st.write(result.get('question', '').strip())\n",
    "\n",
    "        st.subheader(\"Resposta:\")\n",
    "        st.write(result.get('answer', 'Sem resposta disponível').strip())\n",
    "\n",
    "        # Exibição dos documentos recuperados\n",
    "        st.subheader(\"Documentos Recuperados:\")\n",
    "        for i, doc in enumerate(result.get('context', []), 1):\n",
    "            st.markdown(f\"**Documento {i}:**\")\n",
    "            st.markdown(f\"**Fonte:** {doc.metadata.get('source', '').strip()}\")\n",
    "            st.markdown(f\"**Conteúdo:** {doc.page_content[:500].strip()}...\")\n",
    "\n",
    "        # Preparação dos resultados de avaliação\n",
    "        evaluation_result = {\n",
    "            'query': result.get('question', ''),\n",
    "            'result': result.get('answer', ''),\n",
    "            'source_documents': result.get('context', []),\n",
    "        }\n",
    "\n",
    "        # Avaliação das métricas\n",
    "        try:\n",
    "            with st.spinner('Calculando métricas RAGAS...'):\n",
    "                faithfulness_score = evaluate(faithfulness, evaluation_result)\n",
    "                answer_relevancy_score = evaluate(answer_relevancy, evaluation_result)\n",
    "                context_precision_score = evaluate(context_precision, evaluation_result)\n",
    "                context_recall_score = evaluate(context_recall, evaluation_result)\n",
    "\n",
    "            # Exibição dos resultados de avaliação\n",
    "            st.subheader(\"Métricas de Avaliação RAGAS:\")\n",
    "            st.write(f\"**Pontuação de Fidelidade:** {faithfulness_score:.2f}\")\n",
    "            st.write(f\"**Pontuação de Relevância da Resposta:** {answer_relevancy_score:.2f}\")\n",
    "            st.write(f\"**Pontuação de Precisão do Contexto:** {context_precision_score:.2f}\")\n",
    "            st.write(f\"**Pontuação de Revocação do Contexto:** {context_recall_score:.2f}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            st.error(f\"Erro ao calcular métricas RAGAS: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-18 10:03:34.737 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-18 10:03:34.737 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-18 10:03:34.738 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-18 10:03:34.738 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-18 10:03:34.738 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-18 10:03:34.738 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-18 10:03:34.739 Session state does not function when running a script without `streamlit run`\n",
      "2024-12-18 10:03:34.739 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-18 10:03:34.739 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
